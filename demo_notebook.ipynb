{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd243172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datadrive5/huypn16/anaconda3/envs/ana/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-06 06:40:10,972\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "os.sys.path.append(\"/datadrive5/huypn16/ICV\")\n",
    "\n",
    "from models import build_tokenizer, build_model\n",
    "from tasks import load_task\n",
    "from utils.llm_layers import add_icv_layers, remove_icv_layers\n",
    "\n",
    "from vllm import EngineArgs, LLMEngine, SamplingParams\n",
    "from vllm.control_vectors.request import ControlVectorRequest\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7407de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-06 06:40:12 llm_engine.py:200] Initializing an LLM engine (v0.5.5) with config: model='Qwen/Qwen2.5-7B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, return_hidden_states=True, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-7B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 10-06 06:40:13 model_runner.py:909] Starting to load model Qwen/Qwen2.5-7B-Instruct...\n",
      "INFO 10-06 06:40:13 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.21it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.87it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.75it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.75it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.79it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-06 06:40:16 model_runner.py:920] Loading model weights took 14.2487 GB\n",
      "INFO 10-06 06:40:20 gpu_executor.py:123] # GPU blocks: 57734, # CPU blocks: 4681\n",
      "INFO 10-06 06:40:25 model_runner.py:1239] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 10-06 06:40:25 model_runner.py:1243] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 10-06 06:40:37 model_runner.py:1358] Graph capturing finished in 13 secs.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "engine_args = EngineArgs(model=MODEL_PATH, enable_control_vector=True, gpu_memory_utilization=0.95, return_hidden_states=True)\n",
    "engine = LLMEngine.from_engine_args(engine_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ed479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_path = \"/datadrive5/huypn16/ICV/controlvector.gguf\"\n",
    "\n",
    "\n",
    "def generate_n_get_icv(bases, engine, max_tokens=2000):\n",
    "    prompts = [\n",
    "        (base, SamplingParams(temperature=0.0, max_tokens=max_tokens), None) for base in bases\n",
    "    ]\n",
    "    request_id = 0\n",
    "    results = set()\n",
    "    \n",
    "    icvs = {}\n",
    "    \n",
    "    # icv_pair = {\"base\": None, \"next\": None}\n",
    "    \n",
    "    while prompts or engine.has_unfinished_requests():\n",
    "        if prompts:\n",
    "            prompt, sampling_params, cv_request = prompts.pop(0)\n",
    "            engine.add_request(str(request_id), prompt, sampling_params, control_vector_request=cv_request)\n",
    "            request_id += 1\n",
    "\n",
    "        request_outputs = engine.step()\n",
    "        for request_output in request_outputs:\n",
    "            if request_output.finished or request_output.outputs[0].prompt_hidden_states != None:\n",
    "                results.add((request_output.request_id, request_output.outputs[0].text))\n",
    "                if icvs.get(request_output.request_id) == None:\n",
    "                    icvs[request_output.request_id] = {\"base\": None, \"next\": None}\n",
    "                if request_output.outputs[0].prompt_hidden_states != None:\n",
    "                    icvs[request_output.request_id][\"base\"] = request_output.outputs[0].prompt_hidden_states\n",
    "                icvs[request_output.request_id][\"next\"] = request_output.outputs[0].hidden_states                  \n",
    "        if len(results) == len(bases):\n",
    "            break\n",
    "    \n",
    "    ordered_requests = sorted(results, key=lambda x: int(x[0]))\n",
    "    ordered_icvs = sorted(icvs.items(), key=lambda x: int(x[0]))\n",
    "    \n",
    "    for icv in ordered_icvs:\n",
    "        icv[1][\"difference\"] = icv[1][\"next\"] - icv[1][\"base\"]\n",
    "    \n",
    "    final_output = [(req[1], icv[1][\"difference\"]) for req, icv in zip(ordered_requests, ordered_icvs)]\n",
    "    return final_output\n",
    "    \n",
    "bases = [\"Solving the following mathematical problem. Problem: Calculate the following expression: (10222 + 23123123 * 4 - 1 ) * 5 - 6. Step 1:\" ]\n",
    "\n",
    "output = generate_n_get_icv(bases, engine, max_tokens=2000)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd210c",
   "metadata": {},
   "source": [
    "# Task 1: Dialogue safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b779d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "Problem:  Let $(a_1,b_1),$ $(a_2,b_2),$ $\\dots,$ $(a_n,b_n)$ be all the ordered pairs $(a,b)$ of complex numbers with $a^2+b^2\\\\neq 0,$\n",
    "\\[a+\\\\frac{10b}{a^2+b^2}=5, \\quad \\\\text{and} \\quad b+\\\\frac{10a}{a^2+b^2}=4.\\]Find $a_1 + b_1 + a_2 + b_2 + \\dots + a_n + b_n.$ \n",
    "\n",
    "#### Step 1: If $a = 0,$ then $\\\\frac{10}{b} = 5,$ so $b = 2,$ which does not satisfy the second equation.\n",
    "\n",
    "#### Step 2: If $b = 0,$ then $\\\\frac{10}{a} = 4,$ so $a = \\\\frac{5}{2},$ which does not satisfy the first equation.\n",
    "\n",
    "#### Step 3: So, we can assume that both $a$ and $b$ are nonzero.\n",
    "\n",
    "#### Step 4: Then $\\\\frac{5 - a}{b} = \\\\frac{4 - b}{a} = \\\\frac{10}{a^2 + b^2}.$\n",
    "\n",
    "#### Step 5: \\[\\\\frac{5b - ab}{b^2} = \\\\frac{4a - ab}{a^2} = \\\\frac{10}{a^2 + b^2},\\]so\n",
    "\\[\\\\frac{4a + 5b - 2ab}{a^2 + b^2} = \\\\frac{10}{a^2 + b^2},\\]so $4a + 5b - 2ab = 10.$\n",
    "\n",
    "#### Step 6: Then $2ab - 4a - 5b + 10 = 0,$ which factors as $(2a - 5)(b - 2) = 0.$  Hence, $a = \\\\frac{5}{2}$ or $b = 2.$\"\"\"\n",
    "\n",
    "suffix = \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then \\[\\\\frac{5/2}{b} = \\\\frac{10}{\\\\frac{25}{4} + b^2}.\\]. This simplifies to $4b^2 - 16b + 25 = 0.$  By the quadratic formula,\n",
    "\\[b = 2 \\pm \\\\frac{3i}{2}.\\]\"\"\"\n",
    "math_directions = [(prefix + suffix, prefix + \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then\n",
    "\\[\\\\frac{5}{2} + \\\\frac{20b}{\\\\frac{25}{4} + b^2} = 5,\\]so $\\\\frac{20b}{\\\\frac{25}{4} + b^2} = \\\\frac{5}{2},$ so $\\\\frac{b}{\\\\frac{5}{4} + b^2} = \\\\frac{1}{4},$ so $4b = \\\\frac{5}{4} + b^2,$ so $b^2 - 4b + \\\\frac{5}{4} = 0.$\"\"\"),\n",
    "                   (prefix + suffix, prefix + \"#### Step 7: If $a = \\\\frac{5}{2},$ then $\\\\frac{10}{b} = 5,$ so $b = 2.$\"),\n",
    "                   (prefix + suffix, prefix + \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then $\\\\frac{5}{2} + \\\\frac{10b}{\\\\frac{25}{4} + b^2} = 5.$  Letting $k = b^2,$ we get\"\"\"),\n",
    "                   (prefix + suffix, prefix + \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then\n",
    "\\begin{align*}\n",
    "\\frac{10}{a^2 + b^2} &= 4, \\\\\n",
    "\\frac{10}{\\frac{25}{4} + b^2} &= 4, \\\\\n",
    "10 &= 4 \\left( \\frac{25}{4} + b^2 \\right), \\\\\n",
    "10 &= 25 + 4b^2, \\\\\n",
    "4b^2 &= -15,\n",
    "\\end{align*}which is impossible.\"\"\")]\n",
    "rewards = [0.5927, 0.5312, 0.4688, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dacc9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Solving the following mathematical problem\n",
    "Problem: Calculate the following expression: (4 + 3 * 2 - 1 ) * 4 - 2.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"Step 1: First, we add 4 and 3 to get 7.\"\"\"\n",
    "\n",
    "math_directions = [(prefix + suffix, prefix + \"Step 1: First, we minus 1 from 2 to get 1.\"), # 0\n",
    "                   (prefix + suffix, prefix + \"Step 1: First, we multiply 3 by 2 to get 6.\"), # 0.7\n",
    "                   (prefix + suffix, prefix + \"Step 1: First, we minus 2 from 4 to get 2.\"), # 0\n",
    "                   (prefix + suffix, prefix + \"Step 1: First, we calculate the expression inside the parentheses to get 3*2 = 6, and then we add 4 to get 10.\")] # 1\n",
    "rewards = [1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fe24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = [\"Solving the following mathematical problem. Problem: Calculate the following expression: (4 + 3 * 2 - 1 ) * 4 - 2. Step 1: First, we add 4 and 3 to get 7.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 23 * 4 - 1 ) * 3 - 2. Step 1: First, we add 12 and 23 to get 35.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (34 + 2231 * 6 - 1 ) * 34 - 2. Step 1: First, we add 34 and 2231 to get 2265.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 123 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 123 to get 135.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12445 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 12445 to get 12457.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12446 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 123 to get 12458.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12447 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 123 to get 12459.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 1000 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 1000 to get 1012.\",]\n",
    "\n",
    "\n",
    "basesteps = [\"Solving the following mathematical problem. Problem: Calculate the following expression: (4 + 3 * 2 - 1 ) * 4 - 3111.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 23 * 4 - 1 ) * 3 - 1245.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (34 + 2231 * 6 - 1 ) * 34 - 123.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 123 * 2 - 1 ) * 412 - 123.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12445 * 2 - 1 ) * 412 - 2.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12446 * 2 - 1 ) * 412 - 2.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12447 * 2 - 1 ) * 412 - 2.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 1000 * 2 - 1 ) * 412 - 2.\",]\n",
    "\n",
    "# math_directions = [(prefix + suffix, prefix + \"Step 1: First, we minus 1 from 2 to get 1.\"), # 0\n",
    "#                    (prefix + suffix, prefix + \"Step 1: First, we multiply 3 by 2 to get 6.\"), # 0.7\n",
    "#                    (prefix + suffix, prefix + \"Step 1: First, we minus 2 from 4 to get 2.\"), # 0\n",
    "#                    (prefix + suffix, prefix + \"Step 1: First, we calculate the expression inside the parentheses to get 3*2 = 6, and then we add 4 to get 10.\")] # 1\n",
    "# rewards = [1, 0, 1, 0]\n",
    "rewards = [1, 0.881212, 0.78841, 0.945423, 0.8, 0.9, 0.95, 0.9]\n",
    "math_directions = [(basestep, direction) for basestep, direction in zip(basesteps, directions)]\n",
    "prefix = \"Solving the following mathematical problem. Problem: Calculate the following expression: (10222 + 23123123 * 4 - 1 ) * 5 - 6. Step 1:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = 8\n",
    "icv_reward_weighed = task_agent.get_reward(math_directions, rewards=rewards, rank=n_comps\n",
    "        )\n",
    "\n",
    "icv_unweighted, _ = task_agent.obtain_icv(\n",
    "            math_directions, tokenizer, prefix=(\"\", \"\")\n",
    "            ), rank=n_comps\n",
    "        )\n",
    "print(len(icv_reward_weighed))\n",
    "print(len(icv_unweighted))\n",
    "print(icv_reward_weighed[0].shape)\n",
    "print(icv_unweighted[0].shape)\n",
    "\n",
    "query = tokenizer(prefix)\n",
    "\n",
    "for i in range(n_comps):\n",
    "    weighed_direction = icv_reward_weighed[i][1:]\n",
    "    unweighted_direction = icv_unweighted[i][1:]\n",
    "\n",
    "    weighed_direction = [weighed_direction]\n",
    "    unweighted_direction = [unweighted_direction]\n",
    "    lam = 0.2\n",
    "    print(f\"===================={i}th direction===============\")\n",
    "    add_icv_layers(model, torch.stack(unweighted_direction,dim=1).cuda(), [lam])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff700fb",
   "metadata": {},
   "source": [
    "# Original model (Unsafe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_output = model.generate(\n",
    "                        input_ids=torch.tensor(query['input_ids']).unsqueeze(0).cuda(),\n",
    "                        attention_mask=torch.tensor(query['attention_mask']).unsqueeze(0).cuda(),\n",
    "                        max_new_tokens=100,\n",
    "                        temperature = 0.65,\n",
    "                        do_sample=True,\n",
    "                        top_k=10,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=[198, tokenizer.eos_token_id]\n",
    "                    )\n",
    "print(generation_output)\n",
    "decoded_output = tokenizer.decode(generation_output[0])\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12260c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gguf\n",
    "def export_gguf(path: os.PathLike[str] | str, directions: list[torch.Tensor], model):\n",
    "    arch = \"controlvector\"\n",
    "    directions = [directions[i] for i in range(1, len(directions))]\n",
    "    writer = gguf.GGUFWriter(path, arch)\n",
    "    writer.add_string(f\"{arch}.model_hint\", model.config.model_type)\n",
    "    writer.add_uint32(f\"{arch}.layer_count\", len(directions))\n",
    "    for layer, _ in enumerate(directions):\n",
    "        writer.add_tensor(f\"direction.{layer}\", directions[layer].numpy())\n",
    "    writer.write_header_to_file()\n",
    "    writer.write_kv_data_to_file()\n",
    "    writer.write_tensors_to_file()\n",
    "    writer.close()\n",
    "    \n",
    "export_gguf(\"controlvector.gguf\", icv_unweighted[6], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189c5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
