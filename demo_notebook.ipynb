{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd243172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common import setup_env, mk_parser\n",
    "from models import build_model_signature, build_tokenizer, build_model\n",
    "from tasks import load_task\n",
    "from utils.logger import tabular_pretty_print\n",
    "from utils.tools import ensure_folder\n",
    "from utils.pca import PCA\n",
    "from utils.llm_layers import add_icv_layers, remove_icv_layers\n",
    "\n",
    "import numpy as np\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c9cca9-51c7-4c56-8896-514ca5aa6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_each_demonstration(demonstration_list, tokenizer, dataset_name=None, prefix = None):\n",
    "    # special_characters = [\n",
    "    #     \"~\", \" ~\", \"~ \", \"!\", \" !\", \"! \", \"@\", \" @\", \"@ \", \"#\", \" #\", \"# \", \n",
    "    #     \"$\", \" $\", \"$ \", \"%\", \" %\", \"% \", \"^\", \" ^\", \"^ \", \"&\", \" &\", \"& \", \n",
    "    #     \"*\", \" *\", \"* \", \"(\", \" (\", \"( \", \")\", \" )\", \") \", \"_\", \" _\", \"_ \", \n",
    "    #     \"+\", \" +\", \"+ \", \"`\", \" `\", \"` \", \"-\", \" -\", \"- \", \"=\", \" =\", \"= \", \n",
    "    #     \"{\", \" {\", \"{ \", \"}\", \" }\", \"} \", \"[\", \" [\", \"[ \", \"]\", \" ]\", \"] \", \n",
    "    #     \"|\", \" |\", \"| \", \"\\\\\", \" \\\\\", \"\\\\ \", \":\", \" :\", \": \", \";\", \" ;\", \"; \", \n",
    "    #     \"\\\"\", \" \\\"\", \"\\\" \", \"'\", \" '\", \"' \", \"<\", \" <\", \"< \", \">\", \" >\", \"> \", \n",
    "    #     \",\", \" ,\", \", \", \".\", \" .\", \". \", \"?\", \" ?\", \"? \", \"/\", \" /\", \"/ \"\n",
    "    # ]\n",
    "\n",
    "    def strip_special_characters(input_string):\n",
    "        # for char in special_characters:\n",
    "        #     input_string = input_string.replace(char.strip(), '')\n",
    "        return input_string.strip()\n",
    "\n",
    "    tokenized_demonstration_list = []\n",
    "    for exp_id in range(len(demonstration_list)):\n",
    "        if prefix is not None:\n",
    "            demonstration_list[exp_id] = (prefix[0] + strip_special_characters(demonstration_list[exp_id][0]), prefix[1] + strip_special_characters(demonstration_list[exp_id][1]))\n",
    "        else:\n",
    "            demonstration_list[exp_id] = (strip_special_characters(demonstration_list[exp_id][0]), strip_special_characters(demonstration_list[exp_id][1]))\n",
    "        e_original = tokenizer(demonstration_list[exp_id][0]) \n",
    "        e_rewrite = tokenizer(demonstration_list[exp_id][1])\n",
    "        tokenized_demonstration_list.append((e_original, e_rewrite)) \n",
    "    return tokenized_demonstration_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ed479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import EngineArgs, LLMEngine, SamplingParams\n",
    "from vllm.control_vectors.request import ControlVectorRequest\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_PATH = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "cv_path = \"/datadrive5/huypn16/ICV/controlvector.gguf\"\n",
    "\n",
    "\n",
    "def do_sample(engine):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    prompt_text = \"Solving the following mathematical problem. Problem: Calculate the following expression: (10222 + 23123123 * 4 - 1 ) * 5 - 6. Step 1:\" \n",
    "    prompt = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "    print(len(prompt[0]))\n",
    "    \n",
    "    # first prompt with a control vector and second without.\n",
    "    prompts = [(prompt_text,\n",
    "                SamplingParams(temperature=0.65,\n",
    "                               max_tokens=100),\n",
    "                ControlVectorRequest(\"chaotic\", 1, cv_path, scale=1.0)),\n",
    "               (prompt_text,\n",
    "                SamplingParams(temperature=0.0,\n",
    "                               max_tokens=100), None)]\n",
    "\n",
    "    request_id = 0\n",
    "    results = set()\n",
    "    while prompts or engine.has_unfinished_requests():\n",
    "        if prompts:\n",
    "            prompt, sampling_params, cv_request = prompts.pop(0)\n",
    "            engine.add_request(str(request_id),\n",
    "                               prompt,\n",
    "                               sampling_params,\n",
    "                               control_vector_request=cv_request)\n",
    "            request_id += 1\n",
    "\n",
    "        request_outputs = engine.step()\n",
    "        for request_output in request_outputs:\n",
    "            if request_output.finished or request_output.outputs[0].prompt_hidden_states != None:\n",
    "                results.add((request_output.request_id, request_output.outputs[0].text, request_output.outputs[0].hidden_states.shape, request_output.outputs[0].prompt_hidden_states.shape if request_output.outputs[0].prompt_hidden_states != None else None))\n",
    "        if len(results) == 4:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "\n",
    "def test_cv_adapter():\n",
    "    engine_args = EngineArgs(model=MODEL_PATH, enable_control_vector=True, gpu_memory_utilization=0.95, return_hidden_states=True)\n",
    "    engine = LLMEngine.from_engine_args(engine_args)\n",
    "    result = do_sample(engine)\n",
    "    print(list(result))\n",
    "    print(len(result))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_cv_adapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04aede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = build_tokenizer(args.model_type, args.model_size, padding_side='right')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model     = build_model(args.model_type, args.model_size, args.in_8bit)\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "print(f\"Model loaded: {model_signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd210c",
   "metadata": {},
   "source": [
    "# Task 1: Dialogue safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b779d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "Problem:  Let $(a_1,b_1),$ $(a_2,b_2),$ $\\dots,$ $(a_n,b_n)$ be all the ordered pairs $(a,b)$ of complex numbers with $a^2+b^2\\\\neq 0,$\n",
    "\\[a+\\\\frac{10b}{a^2+b^2}=5, \\quad \\\\text{and} \\quad b+\\\\frac{10a}{a^2+b^2}=4.\\]Find $a_1 + b_1 + a_2 + b_2 + \\dots + a_n + b_n.$ \n",
    "\n",
    "#### Step 1: If $a = 0,$ then $\\\\frac{10}{b} = 5,$ so $b = 2,$ which does not satisfy the second equation.\n",
    "\n",
    "#### Step 2: If $b = 0,$ then $\\\\frac{10}{a} = 4,$ so $a = \\\\frac{5}{2},$ which does not satisfy the first equation.\n",
    "\n",
    "#### Step 3: So, we can assume that both $a$ and $b$ are nonzero.\n",
    "\n",
    "#### Step 4: Then $\\\\frac{5 - a}{b} = \\\\frac{4 - b}{a} = \\\\frac{10}{a^2 + b^2}.$\n",
    "\n",
    "#### Step 5: \\[\\\\frac{5b - ab}{b^2} = \\\\frac{4a - ab}{a^2} = \\\\frac{10}{a^2 + b^2},\\]so\n",
    "\\[\\\\frac{4a + 5b - 2ab}{a^2 + b^2} = \\\\frac{10}{a^2 + b^2},\\]so $4a + 5b - 2ab = 10.$\n",
    "\n",
    "#### Step 6: Then $2ab - 4a - 5b + 10 = 0,$ which factors as $(2a - 5)(b - 2) = 0.$  Hence, $a = \\\\frac{5}{2}$ or $b = 2.$\"\"\"\n",
    "\n",
    "suffix = \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then \\[\\\\frac{5/2}{b} = \\\\frac{10}{\\\\frac{25}{4} + b^2}.\\]. This simplifies to $4b^2 - 16b + 25 = 0.$  By the quadratic formula,\n",
    "\\[b = 2 \\pm \\\\frac{3i}{2}.\\]\"\"\"\n",
    "math_directions = [(prefix + suffix, prefix + \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then\n",
    "\\[\\\\frac{5}{2} + \\\\frac{20b}{\\\\frac{25}{4} + b^2} = 5,\\]so $\\\\frac{20b}{\\\\frac{25}{4} + b^2} = \\\\frac{5}{2},$ so $\\\\frac{b}{\\\\frac{5}{4} + b^2} = \\\\frac{1}{4},$ so $4b = \\\\frac{5}{4} + b^2,$ so $b^2 - 4b + \\\\frac{5}{4} = 0.$\"\"\"),\n",
    "                   (prefix + suffix, prefix + \"#### Step 7: If $a = \\\\frac{5}{2},$ then $\\\\frac{10}{b} = 5,$ so $b = 2.$\"),\n",
    "                   (prefix + suffix, prefix + \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then $\\\\frac{5}{2} + \\\\frac{10b}{\\\\frac{25}{4} + b^2} = 5.$  Letting $k = b^2,$ we get\"\"\"),\n",
    "                   (prefix + suffix, prefix + \"\"\"#### Step 7: If $a = \\\\frac{5}{2},$ then\n",
    "\\begin{align*}\n",
    "\\frac{10}{a^2 + b^2} &= 4, \\\\\n",
    "\\frac{10}{\\frac{25}{4} + b^2} &= 4, \\\\\n",
    "10 &= 4 \\left( \\frac{25}{4} + b^2 \\right), \\\\\n",
    "10 &= 25 + 4b^2, \\\\\n",
    "4b^2 &= -15,\n",
    "\\end{align*}which is impossible.\"\"\")]\n",
    "rewards = [0.5927, 0.5312, 0.4688, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dacc9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Solving the following mathematical problem\n",
    "Problem: Calculate the following expression: (4 + 3 * 2 - 1 ) * 4 - 2.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"Step 1: First, we add 4 and 3 to get 7.\"\"\"\n",
    "\n",
    "math_directions = [(prefix + suffix, prefix + \"Step 1: First, we minus 1 from 2 to get 1.\"), # 0\n",
    "                   (prefix + suffix, prefix + \"Step 1: First, we multiply 3 by 2 to get 6.\"), # 0.7\n",
    "                   (prefix + suffix, prefix + \"Step 1: First, we minus 2 from 4 to get 2.\"), # 0\n",
    "                   (prefix + suffix, prefix + \"Step 1: First, we calculate the expression inside the parentheses to get 3*2 = 6, and then we add 4 to get 10.\")] # 1\n",
    "rewards = [1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fe24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = [\"Solving the following mathematical problem. Problem: Calculate the following expression: (4 + 3 * 2 - 1 ) * 4 - 2. Step 1: First, we add 4 and 3 to get 7.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 23 * 4 - 1 ) * 3 - 2. Step 1: First, we add 12 and 23 to get 35.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (34 + 2231 * 6 - 1 ) * 34 - 2. Step 1: First, we add 34 and 2231 to get 2265.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 123 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 123 to get 135.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12445 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 12445 to get 12457.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12446 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 123 to get 12458.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12447 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 123 to get 12459.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 1000 * 2 - 1 ) * 412 - 2. Step 1: First, we add 12 and 1000 to get 1012.\",]\n",
    "\n",
    "\n",
    "basesteps = [\"Solving the following mathematical problem. Problem: Calculate the following expression: (4 + 3 * 2 - 1 ) * 4 - 3111.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 23 * 4 - 1 ) * 3 - 1245.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (34 + 2231 * 6 - 1 ) * 34 - 123.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 123 * 2 - 1 ) * 412 - 123.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12445 * 2 - 1 ) * 412 - 2.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12446 * 2 - 1 ) * 412 - 2.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 12447 * 2 - 1 ) * 412 - 2.\",\n",
    "             \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 1000 * 2 - 1 ) * 412 - 2.\",]\n",
    "\n",
    "# math_directions = [(prefix + suffix, prefix + \"Step 1: First, we minus 1 from 2 to get 1.\"), # 0\n",
    "#                    (prefix + suffix, prefix + \"Step 1: First, we multiply 3 by 2 to get 6.\"), # 0.7\n",
    "#                    (prefix + suffix, prefix + \"Step 1: First, we minus 2 from 4 to get 2.\"), # 0\n",
    "#                    (prefix + suffix, prefix + \"Step 1: First, we calculate the expression inside the parentheses to get 3*2 = 6, and then we add 4 to get 10.\")] # 1\n",
    "# rewards = [1, 0, 1, 0]\n",
    "rewards = [1, 0.881212, 0.78841, 0.945423, 0.8, 0.9, 0.95, 0.9]\n",
    "math_directions = [(basestep, direction) for basestep, direction in zip(basesteps, directions)]\n",
    "prefix = \"Solving the following mathematical problem. Problem: Calculate the following expression: (10222 + 23123123 * 4 - 1 ) * 5 - 6. Step 1:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskHandler = load_task(args.dataset)\n",
    "print(f\"Task loaded: {args.dataset}\")\n",
    "task_agent = TaskHandler(args.prompt_version)\n",
    "task_agent.set_seed(args.seed)\n",
    "\n",
    "n_comps = 8\n",
    "icv_reward_weighed = task_agent.get_reward(\n",
    "        model, tokenize_each_demonstration(\n",
    "            math_directions, tokenizer, prefix=(\"\", \"\")\n",
    "            ),rewards=rewards, rank=n_comps\n",
    "        )\n",
    "\n",
    "icv_unweighted, _ = task_agent.obtain_icv(\n",
    "        model, tokenize_each_demonstration(\n",
    "            math_directions, tokenizer, prefix=(\"\", \"\")\n",
    "            ), rank=n_comps\n",
    "        )\n",
    "print(len(icv_reward_weighed))\n",
    "print(len(icv_unweighted))\n",
    "print(icv_reward_weighed[0].shape)\n",
    "print(icv_unweighted[0].shape)\n",
    "\n",
    "query = tokenizer(prefix)\n",
    "\n",
    "for i in range(n_comps):\n",
    "    weighed_direction = icv_reward_weighed[i][1:]\n",
    "    unweighted_direction = icv_unweighted[i][1:]\n",
    "\n",
    "    weighed_direction = [weighed_direction]\n",
    "    unweighted_direction = [unweighted_direction]\n",
    "    lam = 0.2\n",
    "    print(f\"===================={i}th direction===============\")\n",
    "    add_icv_layers(model, torch.stack(unweighted_direction,dim=1).cuda(), [lam])\n",
    "    generation_output = model.generate(\n",
    "                            input_ids=torch.tensor(query['input_ids']).unsqueeze(0).cuda(),\n",
    "                            attention_mask=torch.tensor(query['attention_mask']).unsqueeze(0).cuda(),\n",
    "                            do_sample=True,\n",
    "                            temperature = 0.65,\n",
    "                            num_return_sequences=1,\n",
    "                            max_new_tokens=300,\n",
    "                            eos_token_id=[198, tokenizer.eos_token_id]\n",
    "                        )\n",
    "    decoded_output = tokenizer.decode(generation_output[0])\n",
    "    print(\"Unweighted: \",decoded_output)\n",
    "    remove_icv_layers(model)\n",
    "    \n",
    "    lam = 0.2\n",
    "    add_icv_layers(model, torch.stack(weighed_direction,dim=1).cuda(), [lam])\n",
    "    generation_output = model.generate(\n",
    "                            input_ids=torch.tensor(query['input_ids']).unsqueeze(0).cuda(),\n",
    "                            attention_mask=torch.tensor(query['attention_mask']).unsqueeze(0).cuda(),\n",
    "                            do_sample=True,\n",
    "                            top_k=10,\n",
    "                            temperature = 0.65,\n",
    "                            num_return_sequences=1,\n",
    "                            max_new_tokens=400,\n",
    "                            eos_token_id=[tokenizer.eos_token_id]\n",
    "                        )\n",
    "    decoded_output = tokenizer.decode(generation_output[0])\n",
    "    print(\"Weighted: \",decoded_output)\n",
    "    remove_icv_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff700fb",
   "metadata": {},
   "source": [
    "# Original model (Unsafe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_output = model.generate(\n",
    "                        input_ids=torch.tensor(query['input_ids']).unsqueeze(0).cuda(),\n",
    "                        attention_mask=torch.tensor(query['attention_mask']).unsqueeze(0).cuda(),\n",
    "                        max_new_tokens=100,\n",
    "                        temperature = 0.65,\n",
    "                        do_sample=True,\n",
    "                        top_k=10,\n",
    "                        num_return_sequences=1,\n",
    "                        eos_token_id=[198, tokenizer.eos_token_id]\n",
    "                    )\n",
    "print(generation_output)\n",
    "decoded_output = tokenizer.decode(generation_output[0])\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12260c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gguf\n",
    "def export_gguf(path: os.PathLike[str] | str, directions: list[torch.Tensor], model):\n",
    "    arch = \"controlvector\"\n",
    "    directions = [directions[i] for i in range(1, len(directions))]\n",
    "    writer = gguf.GGUFWriter(path, arch)\n",
    "    writer.add_string(f\"{arch}.model_hint\", model.config.model_type)\n",
    "    writer.add_uint32(f\"{arch}.layer_count\", len(directions))\n",
    "    for layer, _ in enumerate(directions):\n",
    "        writer.add_tensor(f\"direction.{layer}\", directions[layer].numpy())\n",
    "    writer.write_header_to_file()\n",
    "    writer.write_kv_data_to_file()\n",
    "    writer.write_tensors_to_file()\n",
    "    writer.close()\n",
    "    \n",
    "export_gguf(\"controlvector.gguf\", icv_unweighted[6], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189c5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
